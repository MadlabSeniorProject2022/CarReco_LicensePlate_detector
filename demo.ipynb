{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import lean_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lean_detect import UseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  e12f9b8 torch 1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191.375MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PPUNN\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 306 layers, 36905341 parameters, 36905341 gradients, 104.5 GFLOPS\n",
      "c:\\Users\\PPUNN\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:561: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  if param.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vehicle_detect = UseModel(\"yolov7.pt\", detect_class=[2, 5, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  e12f9b8 torch 1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8191.375MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lpd_detect = UseModel(\"LPD100x.pt\", confident=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def plate_do (coor, img, conf, cls):\n",
    "    crop_img = img[ int(coor[1]) : int(coor[3]), int(coor[0]): int(coor[2])]\n",
    "    cv2.imwrite(\"./okl.png\", crop_img)\n",
    "\n",
    "def vehicle_do (coor, img, conf, cls):\n",
    "    crop_img = img[ int(coor[1]) : int(coor[3]), int(coor[0]): int(coor[2])]\n",
    "    cv2.imwrite(\"./ok.png\", crop_img)\n",
    "    lpd_detect.detect(\"./ok.png\", do_function=plate_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PPUNN\\Documents\\FinalProj\\Yolo_img_detect_boilerplate\\inference\\images\\b.jpg\n",
      "find\n",
      "c:\\Users\\PPUNN\\Documents\\FinalProj\\Yolo_img_detect_boilerplate\\ok.png\n",
      "find\n"
     ]
    }
   ],
   "source": [
    "vehicle_detect.detect(\"inference/images/b.jpg\", do_function=vehicle_do)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b67c5afb4a213e8fbdf683749ef35faca1ebc3e9a9bee2db524cf59386cbbd09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
